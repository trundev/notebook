{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load source data\n",
    "SIGNALS_FILE = 'falstad-data/CAN_signals.csv'\n",
    "\n",
    "FREQUENCY_SIGNAL = 'ESP_m_Raddrehz'\n",
    "POSITION_SIGNAL = 'ESP_Wegimp_VA'\n",
    "POSITION_WRAPVAL = 1<<11\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(SIGNALS_FILE, index_col='time')\n",
    "\n",
    "# Index can be a Unix-epoch time\n",
    "if df.index.max() > 1e6:\n",
    "    df.index = pd.to_datetime(df.index, unit='s')\n",
    "\n",
    "#\n",
    "# Tools\n",
    "#\n",
    "def unwrap_column(ser: pd.Series, wrap_val: float) -> None:\n",
    "    \"\"\"Adjust wrapped around column (change of more than half of the wrap-around value)\"\"\"\n",
    "    mask = ser.notna()\n",
    "    data = ser[mask].values\n",
    "    wraps = abs(data[1:] - data[:-1]) > wrap_val/2\n",
    "    wraps = wraps.nonzero()[0]\n",
    "    for idx in wraps:\n",
    "        adj = wrap_val if data[idx] > data[idx+1] else -wrap_val\n",
    "        data[idx+1:] += adj\n",
    "    ser.mask(mask, other=data, inplace=True)\n",
    "def date2offset(dates:pd.DatetimeIndex or pd.Index, start:pd.Timestamp or float) -> pd.Index:\n",
    "    \"\"\"Convert dates to float offsets\"\"\"\n",
    "    if isinstance(dates, pd.DatetimeIndex):\n",
    "        return (dates - start).astype(int) / 1e9\n",
    "    return dates - start\n",
    "def offset2date(date:pd.Index, start:pd.Timestamp or float) -> pd.DatetimeIndex:\n",
    "    \"\"\"Convert float offsets to dates\"\"\"\n",
    "    if isinstance(start, pd.Timestamp):\n",
    "        return pd.to_timedelta(date, unit='s') + start\n",
    "    return date + start\n",
    "\n",
    "# Detect and adjust wrap-arounds in 'ESP_Wegimp_VA\n",
    "position_raw = None\n",
    "if POSITION_SIGNAL in df.columns:\n",
    "    position_raw = df[POSITION_SIGNAL].copy()\n",
    "    unwrap_column(df[POSITION_SIGNAL], POSITION_WRAPVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize source data\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.FigureWidget()\n",
    "\n",
    "# Reorder columns\n",
    "if POSITION_SIGNAL in df.columns and FREQUENCY_SIGNAL in df.columns:\n",
    "    df = df[[POSITION_SIGNAL, FREQUENCY_SIGNAL]]\n",
    "\n",
    "fig.update_layout(\n",
    "        title='Source data',\n",
    "        hovermode='x unified',\n",
    "        yaxis2=dict(overlaying='y', side='right'),\n",
    "        # The rest of colums are without axis\n",
    "        **dict.fromkeys(['yaxis%d'%i for i in range(3, len(df.columns)+1)], dict(overlaying='y', visible=False))\n",
    "    )\n",
    "\n",
    "for idx, column in enumerate(df.columns):\n",
    "    ser = df[column].dropna()\n",
    "    fig.add_scatter(x=ser.index, y=ser, yaxis='y%d'%(idx+1), name=column)\n",
    "\n",
    "# Add original (unwrapped) position \n",
    "if position_raw is not None:\n",
    "    fig.add_scatter(x=position_raw.index, y=position_raw, yaxis='y1', line_dash='dash',\n",
    "            visible='legendonly', name=POSITION_SIGNAL + ' (raw)')\n",
    "\n",
    "fig.update_traces(xhoverformat='%s.%L')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize approximated derivatives\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import poly_approx\n",
    "\n",
    "MAX_DERIVS = 6\n",
    "NUM_DERIVS = 4\n",
    "SRC_FREQ_SCALE = 100\n",
    "\n",
    "approx = poly_approx.approximator()\n",
    "\n",
    "# Allow data pre-procesing / reduction of the sample rate\n",
    "start_t = df.index[0]\n",
    "\n",
    "# Obtain the signal values\n",
    "ser = df[POSITION_SIGNAL]\n",
    "ser = ser.dropna()      # Drop missing values\n",
    "src_data = np.array((ser, date2offset(ser.index, start_t))).T\n",
    "\n",
    "def lin_filter(arr: np.array, width: int, *, axis: int=0) -> np.array:\n",
    "    \"\"\"Linear (averaging) filter of array\"\"\"\n",
    "    idx = np.arange(arr.shape[axis] - width + 1) + np.arange(width)[...,np.newaxis]\n",
    "    return np.take(arr, idx, axis=axis).sum(axis) / width\n",
    "\n",
    "fig = go.FigureWidget()\n",
    "fig.update_layout(\n",
    "    title='Approximated derivatives',\n",
    "    hovermode='x unified',\n",
    "    yaxis2=dict(overlaying='y', side='right'),\n",
    "    yaxis3=dict(overlaying='y', visible=False),\n",
    "    yaxis4=dict(overlaying='y', visible=False))\n",
    "\n",
    "# Prepare scatter data from 4 derivatives\n",
    "scat_vals = tuple(([],[]) for _ in range(NUM_DERIVS or 4))\n",
    "\n",
    "# Experimental filtering\n",
    "if False:\n",
    "    # Replace time (index)\n",
    "    src_data[...,1] = np.linspace(src_data[0,1], src_data[-1,1], src_data.shape[0], endpoint=True)\n",
    "if False:\n",
    "    # Blur data (index and position)\n",
    "    for _ in range(4):\n",
    "        src_data = lin_filter(src_data, 10) # 10 ~ .5 sec\n",
    "\n",
    "for v, t in src_data:\n",
    "    approx.approximate(v, t)\n",
    "    # Drop high-rank components\n",
    "    if MAX_DERIVS is not None:\n",
    "        approx.reduce(max_rank=MAX_DERIVS)\n",
    "    tmp_obj = approx.copy()\n",
    "    # Convert to derivatives\n",
    "    if NUM_DERIVS is not None:\n",
    "        d_idx = min(NUM_DERIVS, tmp_obj.num_deltas()) - 1\n",
    "        d_time = tmp_obj.get_value_time(d_idx)[1]\n",
    "        tmp_obj.make_derivs(time=d_time, delta_rank=d_idx)\n",
    "    for idx, scatt in zip(range(tmp_obj.num_deltas()), scat_vals):\n",
    "        v, t = tmp_obj.get_value_time(idx, as_deriv=True)\n",
    "        scatt[0].append(t)\n",
    "        scatt[1].append(v)\n",
    "\n",
    "for idx, scatt in enumerate(scat_vals):\n",
    "    fig.add_scatter(x=offset2date(scatt[0], start_t), y=scatt[1], yaxis='y%d'%(idx+1), name='Deriv%d'%idx,\n",
    "            visible=True if idx<2 else 'legendonly')\n",
    "\n",
    "# Source data for reference (scaled)\n",
    "if POSITION_SIGNAL in df.columns:\n",
    "    ser = df[POSITION_SIGNAL].dropna()\n",
    "    fig.add_scatter(x=ser.index, y=ser, mode='markers',\n",
    "            yaxis='y1', name='Position', visible='legendonly')\n",
    "if FREQUENCY_SIGNAL in df.columns:\n",
    "    ser = df[FREQUENCY_SIGNAL].dropna() * SRC_FREQ_SCALE\n",
    "    fig.add_scatter(x=ser.index, y=ser,\n",
    "            yaxis='y2', name='Frequency', visible='legendonly')\n",
    "\n",
    "fig.update_traces(xhoverformat='%s.%L (%M:%S)')\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7fa85d4e0bb603928aa2cfafc0d513c574ae8c4be606502e86c5955152160dc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv-jupyter')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
